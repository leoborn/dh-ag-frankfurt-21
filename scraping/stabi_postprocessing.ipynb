{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# With this, we can use regular expressions.\n",
    "import re\n",
    "# We import this sub-class for easy generation of frequency distributions.\n",
    "from nltk import FreqDist\n",
    "# This library is for normalizing dates.\n",
    "import dateparser\n",
    "# This is the NLP toolkit we use.\n",
    "import spacy\n",
    "# We initialize a German NLP pipeline with the medium-sized language model.\n",
    "nlp = spacy.load('de_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6331460",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"japanese_students.json\") as json_file:\n",
    "  data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91929d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of students:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35881f2",
   "metadata": {},
   "source": [
    "# Student name processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dba9e9",
   "metadata": {},
   "source": [
    "## Task: Separate Japanese from Romaji names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a regular expression for a sequence of unicode characters in the CJK range.\n",
    "JAPANESE_CHARACTERS_PATTERN = r'[\\u4e00-\\u9fff]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for student in data:\n",
    "  print(student)\n",
    "  name = student['Name']\n",
    "  jap_characters_found = re.findall(JAPANESE_CHARACTERS_PATTERN, name)\n",
    "  print(jap_characters_found)\n",
    "  # This means that no Japanese characters appear in the name.\n",
    "  if len(jap_characters_found) == 0:\n",
    "    print(\"No Japanese name!\")\n",
    "    print(\"Romaji name:\", name)\n",
    "  else:\n",
    "    name_jpn = name.split(\" \")[-1]\n",
    "    print(\"Japanese Name:\", name_jpn)\n",
    "    name_romaji = \" \".join(name.split(\" \")[:-1])\n",
    "    print(\"Romaji Name:\", name_romaji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57ad1f",
   "metadata": {},
   "source": [
    "# Student date processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e07fef",
   "metadata": {},
   "source": [
    "## Task: Parse all given dates and get all birth years and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98052663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might encounter ill-formed dates, so we set a counter to see how many dates could not be parsed.\n",
    "unparseable_dates = 0\n",
    "# We initialize an empty List to collect all parsed birth years.\n",
    "birth_year_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcccc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for student in data:\n",
    "  dates = student['Daten']\n",
    "  # Dates are given in the format date1–date2.\n",
    "  print(\"Birth and death dates:\", dates)\n",
    "  # We separate them by splitting at \"–\".\n",
    "  date_list = dates.strip().split(\"–\")\n",
    "  # We are only interested in dates that are not just \"-\".\n",
    "  #\n",
    "  # Examples:\n",
    "  # A date \"-1913\" would result in [\"\",\"1913\"],\n",
    "  # a date \"Juni 1880-\" would result in [\"Juni 1880\",\"\"],\n",
    "  # and a date \"3.4.1857-Dezember 1910\" would result in [\"3.4.1857\", \"Dezember 1910\"].\n",
    "  if len(date_list) == 2:\n",
    "    first_date = date_list[0]\n",
    "    second_date = date_list[1]\n",
    "    if first_date != \"\":\n",
    "      try:\n",
    "        birth_date = dateparser.parse(first_date)\n",
    "        print(\"Birth date:\", birth_date)\n",
    "        print(\"Birth year:\", birth_date.year)\n",
    "        birth_year_list.append(birth_date.year)\n",
    "      except:\n",
    "        print(first_date, \"cannnot be parsed!\")\n",
    "        unparseable_dates += 1\n",
    "    if second_date != \"\":\n",
    "      try:\n",
    "        death_date = dateparser.parse(second_date)\n",
    "        print(\"Death date:\", death_date)\n",
    "        print(\"Death year:\", death_date.year)\n",
    "      except:\n",
    "        print(second_date, \"cannnot be parsed!\")\n",
    "        unparseable_dates += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unparseable_dates, \"dates could not be parsed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(birth_year_list)\n",
    "print(\"Most common birth years and their frequencies:\")\n",
    "print(fdist.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb1d9d",
   "metadata": {},
   "source": [
    "# Student text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade48a2e",
   "metadata": {},
   "source": [
    "## Task 1: Retrieve all visited universities and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with exploring the first five entries.\n",
    "for student in data[:5]:\n",
    "  text = student['Text']\n",
    "  print(\"Student text:\", text)\n",
    "  # Running spacy on the text amounts to calling nlp(text).\n",
    "  parsed_text = nlp(text)\n",
    "  # We can access all named entities using .ents.\n",
    "  for ent in parsed_text.ents:\n",
    "    print(ent, ent.label_)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_universities = []\n",
    "for student in data[:5]:\n",
    "  text = student['Text']\n",
    "  print(\"Student text:\", text)\n",
    "  parsed_text = nlp(text)\n",
    "  for ent in parsed_text.ents:\n",
    "    if ent.text.startswith(\"U \"):\n",
    "      all_universities.append(ent.text)\n",
    "  print()\n",
    "print(\"All universities:\", all_universities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_universities = []\n",
    "for student in data:\n",
    "  text = student['Text']\n",
    "  parsed_text = nlp(text)\n",
    "  for ent in parsed_text.ents:\n",
    "    if ent.text.startswith(\"U \"):\n",
    "      all_universities.append(ent.text)\n",
    "uni_fdist = FreqDist(all_universities)\n",
    "print(\"Most common universities and their frequencies:\")\n",
    "print(uni_fdist.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b8d3d0",
   "metadata": {},
   "source": [
    "## Task 2: Retrieve all place names from the text commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize an empty dictionary.\n",
    "persons_to_text_places = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "for student in data:\n",
    "  name = student['Name']\n",
    "  persons_to_text_places[name] = []\n",
    "  text = student['Text']\n",
    "  parsed_text = nlp(text)\n",
    "  for named_entity in parsed_text.ents:\n",
    "    if named_entity.label_ == \"LOC\":\n",
    "      persons_to_text_places[name].append(named_entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(persons_to_text_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea6218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
